{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYEWa4iMVpHHegTxsQn+OU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malcolmlett/ml-learning/blob/main/Learning_visualisations_v17_onDemandAutoGraphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Visualisations v17: On-demand Auto-Graphing in callbacks\n",
        "Despite significant improvements in how I have written `@tf.function` methods, and I'm still getting a lot of these warnings when doing rapid development with lots of re-runs of experiments:\n",
        "```\n",
        "WARNING:tensorflow:5 out of the last 374 calls to <function ActivityStatsCollectingMixin._accum_activity_stats_internal at 0x7e2dfb532480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "WARNING:tensorflow:5 out of the last 374 calls to <function ValueStatsCollectingMixin._compute_iteration_value_stats at 0x7e2dfb532ac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "WARNING:tensorflow:5 out of the last 374 calls to <function ActivityStatsCollectingMixin._compute_activity_stats at 0x7e2dfb533600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "```\n",
        "\n",
        "It's clear that it's not actually doing re-tracing very often, and probably only because I'm doing lots of module re-loads. So it's not actually a performance problem. But it adds a lot of noise to experiments.\n",
        "\n",
        "I've noticed that TF tends to manually call auto-graph at the start of training. This actually makes sense for my callbacks too. Whatever auto-graphing they come up with will almost certainly be irrelevant on the next run (when doing rapid development). So it makes sense to use programmatic auto-graphing at the start of training, and then to discard that auto-graph afterwards."
      ],
      "metadata": {
        "id": "knsBB0ptiXXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.isdir('repo'):\n",
        "  # discard any local changes and update\n",
        "  !cd repo && git reset --hard HEAD\n",
        "  !cd repo && git fetch\n",
        "else:\n",
        "  !git clone https://github.com/malcolmlett/ml-learning.git repo\n",
        "\n",
        "# lock to revision\n",
        "!cd repo && git checkout f289e95\n",
        "#!cd repo && git pull\n",
        "\n",
        "import sys\n",
        "sys.path.append('repo')\n",
        "\n",
        "import train_observability_toolkit as tot\n",
        "from importlib import reload\n",
        "reload(tot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUa6nc6fkGsf",
        "outputId": "26049c2d-da26-4fe4-d361-412b70eac626"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repo'...\n",
            "remote: Enumerating objects: 1178, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 1178 (delta 6), reused 9 (delta 3), pack-reused 1163 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1178/1178), 83.33 MiB | 17.73 MiB/s, done.\n",
            "Resolving deltas: 100% (714/714), done.\n",
            "Updating files: 100% (37/37), done.\n",
            "Already up to date.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'train_observability_toolkit' from '/content/repo/train_observability_toolkit.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import train_observability_toolkit_test\n",
        "reload(train_observability_toolkit_test)\n",
        "reload(tot)\n",
        "train_observability_toolkit_test.run_test_suite()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRJrmG0akK2s",
        "outputId": "0dc38bb5-416d-4603-a00d-6af6a73bb3dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All train_observability_toolkit tests passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras import layers, models, datasets, optimizers, metrics\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import time\n",
        "import timeit\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "ezvqcFVwk4Cr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics\n"
      ],
      "metadata": {
        "id": "rGXwWePxWwbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_classification_dataset():\n",
        "  np.random.seed(1)\n",
        "  train_X, train_Y = sklearn.datasets.make_circles(n_samples=300, noise=.05)\n",
        "  np.random.seed(2)\n",
        "  test_X, test_Y = sklearn.datasets.make_circles(n_samples=100, noise=.05)\n",
        "  train_X = train_X\n",
        "  train_Y = train_Y.reshape((-1, 1))\n",
        "  test_X = test_X\n",
        "  test_Y = test_Y.reshape((-1, 1))\n",
        "  return train_X, train_Y, test_X, test_Y\n",
        "\n",
        "def mnist_dataset():\n",
        "  np.random.seed(1)\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  # Normalize the data\n",
        "  x_train = x_train / 255.0\n",
        "  return x_train, y_train\n",
        "\n",
        "def binary_classification_model(init_scheme):\n",
        "  \"\"\"\n",
        "  init_scheme: one of \"zeros\", \"large_normal\", \"he_normal\"\n",
        "  \"\"\"\n",
        "  if init_scheme == \"zeros\":\n",
        "    kernel_initializer='zeros'\n",
        "  elif init_scheme == \"large_normal\":\n",
        "    kernel_initializer=tf.keras.initializers.RandomNormal(stddev=10.)\n",
        "  elif init_scheme == \"he_normal\":\n",
        "    kernel_initializer='he_normal'\n",
        "  else:\n",
        "    raise ValueError(\"Unknown init_scheme\")\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(2,)),\n",
        "    tf.keras.layers.Dense(100, activation='relu', kernel_initializer=kernel_initializer),\n",
        "    tf.keras.layers.Dense(100, activation='relu', kernel_initializer=kernel_initializer),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(100, activation='relu', kernel_initializer=kernel_initializer),\n",
        "    tf.keras.layers.Dense(100, activation='relu', kernel_initializer=kernel_initializer),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(100, activation='relu', kernel_initializer=kernel_initializer),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(5, activation='relu', kernel_initializer=kernel_initializer),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer)\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "def mnist_cnn_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(28, 28)),\n",
        "    layers.Reshape((28, 28, 1)),\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=2, activation='relu'),\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=2, activation='relu'),\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', strides=2, activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # Output layer for 10 classes\n",
        "  ])\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "class TimingCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self._start = None\n",
        "    self._epochs = None\n",
        "    self.total = None\n",
        "    self.per_epoch = None\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    if epoch == 1:\n",
        "      self._start = tf.timestamp()\n",
        "    self._epochs = epoch-1\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    self.total = (tf.timestamp() - self._start).numpy()\n",
        "    self.per_epoch = self.total / (self._epochs)"
      ],
      "metadata": {
        "id": "U1Xirh6XWxj4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic implementation\n",
        "Let's first measure this directly and experiment with implementation options."
      ],
      "metadata": {
        "id": "E1MXHIztkMvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This demonstrates it quite nicely.\n",
        "# Re-run this cell block multiple times and you'll get the following approximately every second run:\n",
        "#   WARNING:tensorflow:5 out of the last 5 calls to <function example_function at 0x798d5ef09620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "#   WARNING:tensorflow:6 out of the last 6 calls to <function example_function at 0x798d5ef09620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "def example_function(x):\n",
        "  return x * x\n",
        "\n",
        "example_fn = tf.function(example_function)\n",
        "print(f\"{example_fn.name=}\")\n",
        "print(f\"{example_fn.__name__=}\")\n",
        "print()\n",
        "\n",
        "# Call function with different dtypes (causing retracing)\n",
        "example_fn(tf.constant(3.0))  # float32\n",
        "example_fn(tf.constant(3))    # int32\n",
        "example_fn(tf.constant([1, 2, 3], dtype=tf.float32))  # 1D tensor, float32\n",
        "\n",
        "# Print retracing info\n",
        "print(example_fn.pretty_printed_concrete_signatures())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siZAsI9Zdg4g",
        "outputId": "731394c1-09e5-4f2b-e6a6-eee0c6054eb7"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function example_function at 0x798d74f8fce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function example_function at 0x798d74f8fce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_fn.name='example_function'\n",
            "example_fn.__name__='example_function'\n",
            "\n",
            "Input Parameters:\n",
            "  x (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "Output Type:\n",
            "  TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  None\n",
            "\n",
            "Input Parameters:\n",
            "  x (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
            "Output Type:\n",
            "  TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
            "Captures:\n",
            "  None\n",
            "\n",
            "Input Parameters:\n",
            "  x (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(3,), dtype=tf.float32, name=None)\n",
            "Output Type:\n",
            "  TensorSpec(shape=(3,), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple example callback that just computes the mean-of-means across all values\n",
        "class MyCallback1(tot.BaseGradientCallback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.means = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, loss, gradients, trainable_variables, activations, output_gradients):\n",
        "    self.means.append(self._compute(gradients));\n",
        "\n",
        "  @tf.function\n",
        "  def _compute(self, values):\n",
        "    means = [tf.reduce_mean(tensor) for tensor in values]\n",
        "    mean = tf.reduce_mean(means)\n",
        "    return mean\n",
        "\n",
        "class MyCallback2(tot.BaseGradientCallback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.means = []\n",
        "    self._compute_fn = tf.function(self._compute)\n",
        "\n",
        "  def on_epoch_end(self, epoch, loss, gradients, trainable_variables, activations, output_gradients):\n",
        "    self.means.append(self._compute_fn(gradients));\n",
        "\n",
        "  def _compute(self, values):\n",
        "    means = [tf.reduce_mean(tensor) for tensor in values]\n",
        "    mean = tf.reduce_mean(means)\n",
        "    return mean\n"
      ],
      "metadata": {
        "id": "Bajqj7BYGiKv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Both callbacks seem to perform in almost identical time, but I'm unable to replicate the re-tracing problem\n",
        "reload(tot)\n",
        "tf.config.run_functions_eagerly(False)\n",
        "\n",
        "cb = MyCallback2()\n",
        "timing = TimingCallback()\n",
        "model = binary_classification_model('he_normal')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'mse', 'binary_crossentropy'])\n",
        "train_X, train_Y, _, _ = binary_classification_dataset()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
        "start = tf.timestamp()\n",
        "history = tot.fit(model, dataset.batch(32), epochs=10, verbose=0, callbacks=[tot.LessVerboseProgressLogger(), tot.HistoryStats(), cb, timing])\n",
        "duration = (tf.timestamp() - start).numpy()\n",
        "print(f\"Total training time: {duration:.2f} secs. Average: {timing.per_epoch*1000:.2f}ms/epoch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjiQtrjlkbts",
        "outputId": "0f1e3aae-079b-43f1-c1a8-07fb56768ce8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     1 - 3.44s/epoch: accuracy: 0.5567  binary_crossentropy: 0.6904  loss: 0.6904  mse: 0.2482  \n",
            "Epoch     2 - 107.02ms/epoch: accuracy: 0.5667  binary_crossentropy: 0.6708  loss: 0.6708  mse: 0.2392  \n",
            "Epoch     3 - 58.90ms/epoch: accuracy: 0.6300  binary_crossentropy: 0.6427  loss: 0.6427  mse: 0.2258  \n",
            "Epoch     4 - 60.44ms/epoch: accuracy: 0.6533  binary_crossentropy: 0.6235  loss: 0.6235  mse: 0.2165  \n",
            "Epoch     5 - 57.55ms/epoch: accuracy: 0.6733  binary_crossentropy: 0.6030  loss: 0.6030  mse: 0.2080  \n",
            "Epoch     6 - 60.81ms/epoch: accuracy: 0.6767  binary_crossentropy: 0.5949  loss: 0.5949  mse: 0.2038  \n",
            "Epoch     7 - 60.32ms/epoch: accuracy: 0.7533  binary_crossentropy: 0.5381  loss: 0.5381  mse: 0.1790  \n",
            "Epoch     8 - 64.88ms/epoch: accuracy: 0.7367  binary_crossentropy: 0.5422  loss: 0.5422  mse: 0.1815  \n",
            "Epoch     9 - 58.66ms/epoch: accuracy: 0.7633  binary_crossentropy: 0.5075  loss: 0.5075  mse: 0.1667  \n",
            "Epoch    10 - 60.30ms/epoch: accuracy: 0.7300  binary_crossentropy: 0.5269  loss: 0.5269  mse: 0.1768  \n",
            "Total training time: 4.07 secs. Average: 67.61ms/epoch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb = MyCallback1()\n",
        "timing = TimingCallback()\n",
        "model = binary_classification_model('he_normal')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'mse', 'binary_crossentropy'])\n",
        "train_X, train_Y, _, _ = binary_classification_dataset()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
        "# model = mnist_cnn_model()\n",
        "# train_X, train_Y = mnist_dataset()\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y)).take(32000).batch(64)\n",
        "start = tf.timestamp()\n",
        "history = tot.fit(model, dataset.batch(32), epochs=100, verbose=0, callbacks=[tot.LessVerboseProgressLogger(), tot.HistoryStats(), cb, timing])\n",
        "#history = tot.fit(model, dataset, epochs=10, callbacks=[tot.HistoryStats(), cb , timing])\n",
        "duration = (tf.timestamp() - start).numpy()\n",
        "print(f\"Total training time: {duration:.2f} secs. Average: {timing.per_epoch*1000:.2f}ms/epoch\")"
      ],
      "metadata": {
        "id": "JB55YocEGP4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using existing callbacks"
      ],
      "metadata": {
        "id": "psMD3sXpKY7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here the problem occurs because these different callbacks collect different data from differently shaped tensors, but re-use shared code.\n",
        "# The problem doesn't occur if I only use a single callback.\n",
        "#\n",
        "# Unfortunately, with the code modified to use a simple programmatic tf.function(func_ref) I still get retracing notifications, but worse, now they don't\n",
        "# even mention the function name:\n",
        "#  WARNING:tensorflow:5 out of the last 50 calls to <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x798d5d252ed0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "\n",
        "reload(tot)\n",
        "tf.config.run_functions_eagerly(False)\n",
        "\n",
        "per_step=False\n",
        "variables = tot.VariableHistoryCallback(per_step=per_step, collection_sets=[{}])\n",
        "gradients = tot.GradientHistoryCallback(per_step=per_step, collection_sets=[{}])\n",
        "outputs = tot.LayerOutputHistoryCallback(per_step=per_step, collection_sets=[{}])\n",
        "epoch_gradients = tot.GradientHistoryCallback(per_step=per_step, collection_sets=[{}])\n",
        "output_gradients = tot.LayerOutputGradientHistoryCallback(per_step=per_step, collection_sets=[{}])\n",
        "\n",
        "model = binary_classification_model('he_normal')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'mse', 'binary_crossentropy'])\n",
        "train_X, train_Y, _, _ = binary_classification_dataset()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
        "history = tot.fit(model, dataset.batch(32), epochs=10, verbose=0, callbacks=[tot.LessVerboseProgressLogger(), variables, gradients, epoch_gradients, outputs, output_gradients, tot.HistoryStats(per_step=False)])\n",
        "#history = tot.fit(model, dataset.batch(32), epochs=10, verbose=0, callbacks=[tot.LessVerboseProgressLogger(), output_gradients, tot.HistoryStats(per_step=False)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp07hVnHKc8B",
        "outputId": "54bdaee7-14f7-4dcf-c4b9-d47254a67697"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     1 - 5.16s/epoch: accuracy: 0.6500  binary_crossentropy: 0.7035  loss: 0.7035  mse: 0.2377  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 50 calls to <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x798d5d252ed0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function ValueStatsCollectingMixin._compute_iteration_value_stats at 0x798d652cede0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     2 - 12.23s/epoch: accuracy: 0.6100  binary_crossentropy: 0.6655  loss: 0.6655  mse: 0.2347  \n",
            "Epoch     3 - 461.14ms/epoch: accuracy: 0.6367  binary_crossentropy: 0.6391  loss: 0.6391  mse: 0.2234  \n",
            "Epoch     4 - 531.53ms/epoch: accuracy: 0.6700  binary_crossentropy: 0.6210  loss: 0.6210  mse: 0.2162  \n",
            "Epoch     5 - 248.03ms/epoch: accuracy: 0.7000  binary_crossentropy: 0.5920  loss: 0.5920  mse: 0.2013  \n",
            "Epoch     6 - 272.24ms/epoch: accuracy: 0.7333  binary_crossentropy: 0.5360  loss: 0.5360  mse: 0.1812  \n",
            "Epoch     7 - 254.83ms/epoch: accuracy: 0.7167  binary_crossentropy: 0.5360  loss: 0.5360  mse: 0.1797  \n",
            "Epoch     8 - 302.25ms/epoch: accuracy: 0.7633  binary_crossentropy: 0.5071  loss: 0.5071  mse: 0.1671  \n",
            "Epoch     9 - 248.69ms/epoch: accuracy: 0.7833  binary_crossentropy: 0.5063  loss: 0.5063  mse: 0.1636  \n",
            "Epoch    10 - 255.62ms/epoch: accuracy: 0.7200  binary_crossentropy: 0.5173  loss: 0.5173  mse: 0.1754  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "* I'm giving up for now. It's not worth the effort."
      ],
      "metadata": {
        "id": "Qv6SrZazeIT9"
      }
    }
  ]
}