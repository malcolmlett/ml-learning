{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvdCZPs85ckrCoUtBfgyA6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malcolmlett/ml-learning/blob/main/train_observability_toolkit_theory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Observability Toolkit\n",
        "\n",
        "This file explains the theory behind the operation of the training observability toolkit."
      ],
      "metadata": {
        "id": "EIqLzCJF-wxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explaining Near-zero Gradients\n",
        "The `explain_near_zero_gradients()` function has to reverse engineer some aspects of both the forward and backprop operation of the network. This is may more complex by the fact that technologies like `GradientTape` and `AutoDiff` eliminate the need for layers to expose details about their operation that can be used for mathematical analyses. This section of the docs explains the maths used to perform that reverse-engineering.\n",
        "\n",
        "To explain the underlying cause of a zero or nero-zero gradient, we need to examine the maths behind the gradient computation. The gradient matrix of the weights for a given layer $l$ is defined by:\n",
        "\n",
        "$$\\frac{\\partial{J}}{\\partial{W_l}} ≈ A_{l-1} \\cdot S_l \\cdot \\frac{\\partial{J}}{\\partial{Z_{l+1}}}$$\n",
        "\n",
        "\n",
        "where:\n",
        "* $J$ = loss\n",
        "* $A_{l-1}$ = layer $l-1$ output after activation function applied, ie: output from previous layer as input to layer $l$\n",
        "* $S_l$ = $A_l > 0$ = matrix of 0s and 1s that approximately represents effect of activation function at layer $l$, assuming ReLU activation\n",
        "* $\\frac{\\partial{J}}{\\partial{Z_{l+1}}}$ = backprop from next layer\n",
        "\n",
        "What we really want to compute can be described via a bayesion formalism:\n",
        "\n",
        "$$P(A_{l-1} \\text{causal} | \\frac{\\partial{J}}{\\partial{W_l}} ≈ 0)$$\n",
        "$$P(S_{l} \\text{causal} | \\frac{\\partial{J}}{\\partial{W_l}} ≈ 0)$$\n",
        "$$P(\\frac{\\partial{J}}{\\partial{Z_{l+1}}} \\text{causal} | \\frac{\\partial{J}}{\\partial{W_l}} ≈ 0)$$\n",
        "\n",
        "To do that fully and accurately gets quite involved. So, rather, I merely report on the reverse, and allow the reader to draw their own inferences:\n",
        "\n",
        "$$\n",
        "P(\\frac{\\partial{J}}{\\partial{W_l}} ≈ 0 | A_{l-1}) \\\\\n",
        "P(\\frac{\\partial{J}}{\\partial{W_l}} ≈ 0 | S_l) \\\\\n",
        "P(\\frac{\\partial{J}}{\\partial{W_l}} ≈ 0 | \\frac{\\partial{J}}{\\partial{Z_{l+1}}})$$"
      ],
      "metadata": {
        "id": "mjjlbP3Z_Bhm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4k08M2Lx_Akd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}